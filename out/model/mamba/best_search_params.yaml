batch_size: 128
d_conv: 4
d_model: 32
d_state: 64
dropout: 0.2
epochs: 150
expand: 4
lr: 1.0e-05
num_layers: 1
pooling: last
weight_decay: 0.001
