{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler   \n",
    "from objective import objective_ml_model, objective_dl_model\n",
    "from tester import test_ml_model, test_dl_model\n",
    "from train_pipeline import cv_folds, run_model_pipeline\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Result: [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#=============You can directly load the model for prediction\n",
    "scaler_path = \"./out/model/scaler/scaler.save\"\n",
    "model_path = \"./out/model/logreg/best_model.pth\"\n",
    "data_path = \"./data/mouse_glioma/data_split/test_with_labels.csv\"  #You can replace it with your own data that you wish to predict.\n",
    "df_test = pd.read_csv(data_path).head(5)\n",
    "X_test = df_test.drop(columns=['label', 'ID'], errors='ignore').values\n",
    "y_test = df_test['label'].values if 'label' in df_test.columns else None\n",
    "ids = df_test['ID'].values if 'ID' in df_test.columns else None\n",
    "scaler = joblib.load(scaler_path)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = joblib.load(model_path)\n",
    "preds = model.predict(X_test_scaled)\n",
    "print(\"Prediction Result:\", preds) #0:negative #1:positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 44454\n",
      "Test set size: 9297\n",
      "[âœ“] Saved 5-fold data has been detected and will be loaded directly\n",
      "\n",
      "ðŸ”§ Running model: logreg (ml)\n",
      "A new study created in memory with name: search_for_logreg\n",
      "Trial 0 finished with value: 0.9489835368437343 and parameters: {'C': 0.04656804637919568}. Best is trial 0 with value: 0.9489835368437343.\n",
      "Trial 1 finished with value: 0.9493037518375795 and parameters: {'C': 0.7608481233714796}. Best is trial 1 with value: 0.9493037518375795.\n",
      "Trial 2 finished with value: 0.9498888622951951 and parameters: {'C': 0.001001053986051049}. Best is trial 2 with value: 0.9498888622951951.\n",
      "Trial 3 finished with value: 0.9493764012802588 and parameters: {'C': 0.016193110912440738}. Best is trial 2 with value: 0.9498888622951951.\n",
      "Trial 4 finished with value: 0.9498457609866573 and parameters: {'C': 0.00386387940515873}. Best is trial 2 with value: 0.9498888622951951.\n",
      "Trial 5 finished with value: 0.9499519091678039 and parameters: {'C': 0.0023407464805767528}. Best is trial 5 with value: 0.9499519091678039.\n",
      "Trial 6 finished with value: 0.949778765016678 and parameters: {'C': 0.005559565426712569}. Best is trial 5 with value: 0.9499519091678039.\n",
      "Trial 7 finished with value: 0.9491494533814588 and parameters: {'C': 0.024112537061475744}. Best is trial 5 with value: 0.9499519091678039.\n",
      "Trial 8 finished with value: 0.9490374279523148 and parameters: {'C': 0.03864291653552653}. Best is trial 5 with value: 0.9499519091678039.\n",
      "Trial 9 finished with value: 0.9485877678199157 and parameters: {'C': 0.14297724879798399}. Best is trial 5 with value: 0.9499519091678039.\n",
      "Trial 10 finished with value: 0.9492935304066407 and parameters: {'C': 5.47414146432401}. Best is trial 5 with value: 0.9499519091678039.\n",
      "Trial 11 finished with value: 0.9499778471718754 and parameters: {'C': 0.0014979573000075247}. Best is trial 11 with value: 0.9499778471718754.\n",
      "Trial 12 finished with value: 0.9499151316085988 and parameters: {'C': 0.0010911550069836516}. Best is trial 11 with value: 0.9499778471718754.\n",
      "Trial 13 finished with value: 0.9498430255118702 and parameters: {'C': 0.004252006167337317}. Best is trial 11 with value: 0.9499778471718754.\n",
      "Trial 14 finished with value: 0.9485275751244602 and parameters: {'C': 0.2404916856179318}. Best is trial 11 with value: 0.9499778471718754.\n",
      "Trial 15 finished with value: 0.9496551627901209 and parameters: {'C': 0.009165543855296061}. Best is trial 11 with value: 0.9499778471718754.\n",
      "Trial 16 finished with value: 0.949977585848317 and parameters: {'C': 0.0020816752724588184}. Best is trial 11 with value: 0.9499778471718754.\n",
      "Trial 17 finished with value: 0.9493494270437084 and parameters: {'C': 9.409390081689345}. Best is trial 11 with value: 0.9499778471718754.\n",
      "Trial 18 finished with value: 0.9494012585605163 and parameters: {'C': 0.9060505000736585}. Best is trial 11 with value: 0.9499778471718754.\n",
      "Trial 19 finished with value: 0.949946316319642 and parameters: {'C': 0.002396942306572565}. Best is trial 11 with value: 0.9499778471718754.\n",
      "Trial 20 finished with value: 0.9496761327403471 and parameters: {'C': 0.008604336237920581}. Best is trial 11 with value: 0.9499778471718754.\n",
      "Trial 21 finished with value: 0.9499862029704417 and parameters: {'C': 0.001508738231514904}. Best is trial 21 with value: 0.9499862029704417.\n",
      "Trial 22 finished with value: 0.9500104934845369 and parameters: {'C': 0.0017373179841251034}. Best is trial 22 with value: 0.9500104934845369.\n",
      "Trial 23 finished with value: 0.9499115549053638 and parameters: {'C': 0.0010562410260455417}. Best is trial 22 with value: 0.9500104934845369.\n",
      "Trial 24 finished with value: 0.9495051885461224 and parameters: {'C': 0.012194835144214319}. Best is trial 22 with value: 0.9500104934845369.\n",
      "Trial 25 finished with value: 0.9498429476731888 and parameters: {'C': 0.004043108166644514}. Best is trial 22 with value: 0.9500104934845369.\n",
      "Trial 26 finished with value: 0.9500012399603246 and parameters: {'C': 0.0018660024838094522}. Best is trial 22 with value: 0.9500104934845369.\n",
      "Trial 27 finished with value: 0.9497405585956271 and parameters: {'C': 0.0067152293991905665}. Best is trial 22 with value: 0.9500104934845369.\n",
      "Trial 28 finished with value: 0.9488668181447636 and parameters: {'C': 0.0765582022675851}. Best is trial 22 with value: 0.9500104934845369.\n",
      "Trial 29 finished with value: 0.9491692133457453 and parameters: {'C': 0.03486808367826225}. Best is trial 22 with value: 0.9500104934845369.\n",
      "Trial 30 finished with value: 0.9499196541438237 and parameters: {'C': 0.0026652382983378387}. Best is trial 22 with value: 0.9500104934845369.\n",
      "Trial 31 finished with value: 0.9500131867940171 and parameters: {'C': 0.001752666430181454}. Best is trial 31 with value: 0.9500131867940171.\n",
      "Trial 32 finished with value: 0.9500134665268065 and parameters: {'C': 0.001756107868316339}. Best is trial 32 with value: 0.9500134665268065.\n",
      "Trial 33 finished with value: 0.9494135914252937 and parameters: {'C': 0.017701801502140523}. Best is trial 32 with value: 0.9500134665268065.\n",
      "Trial 34 finished with value: 0.949902946698824 and parameters: {'C': 0.002937886204583646}. Best is trial 32 with value: 0.9500134665268065.\n",
      "Trial 35 finished with value: 0.9499868402677126 and parameters: {'C': 0.0016063007440521046}. Best is trial 32 with value: 0.9500134665268065.\n",
      "Trial 36 finished with value: 0.9497560805779035 and parameters: {'C': 0.006033812009046142}. Best is trial 32 with value: 0.9500134665268065.\n",
      "Trial 37 finished with value: 0.9493908719664811 and parameters: {'C': 0.5728927612186491}. Best is trial 32 with value: 0.9500134665268065.\n",
      "Trial 38 finished with value: 0.949846767248647 and parameters: {'C': 0.003869582966675212}. Best is trial 32 with value: 0.9500134665268065.\n",
      "Trial 39 finished with value: 0.9494799628641971 and parameters: {'C': 0.013009768395237478}. Best is trial 32 with value: 0.9500134665268065.\n",
      "Trial 40 finished with value: 0.949140436200333 and parameters: {'C': 0.025015192832942682}. Best is trial 32 with value: 0.9500134665268065.\n",
      "Trial 41 finished with value: 0.9500057625607369 and parameters: {'C': 0.0016946669109970157}. Best is trial 32 with value: 0.9500134665268065.\n",
      "Trial 42 finished with value: 0.9500165205114287 and parameters: {'C': 0.0017987366576986022}. Best is trial 42 with value: 0.9500165205114287.\n",
      "Trial 43 finished with value: 0.949938279370436 and parameters: {'C': 0.0011648071981827947}. Best is trial 42 with value: 0.9500165205114287.\n",
      "Trial 44 finished with value: 0.949848081075252 and parameters: {'C': 0.0038387148965557073}. Best is trial 42 with value: 0.9500165205114287.\n",
      "Trial 45 finished with value: 0.9498969882377427 and parameters: {'C': 0.0030418879699815925}. Best is trial 42 with value: 0.9500165205114287.\n",
      "Trial 46 finished with value: 0.9497798786377196 and parameters: {'C': 0.005531489915679921}. Best is trial 42 with value: 0.9500165205114287.\n",
      "Trial 47 finished with value: 0.9498901343196365 and parameters: {'C': 0.0010085774525839459}. Best is trial 42 with value: 0.9500165205114287.\n",
      "Trial 48 finished with value: 0.9499911653999522 and parameters: {'C': 0.0015522112827140878}. Best is trial 42 with value: 0.9500165205114287.\n",
      "Trial 49 finished with value: 0.9499762567761401 and parameters: {'C': 0.0020963259236506902}. Best is trial 42 with value: 0.9500165205114287.\n",
      "logreg:{'best_cv_score': 0.9500165205114287, 'best_params': {'C': 0.0017987366576986022}, 'final_train_score': 0.9999994730667081, 'test_score': 0.953569955446563}\n",
      "\n",
      "ðŸ“Š The results of all models: \n",
      "logreg: {'best_cv_score': 0.9500165205114287, 'best_params': {'C': 0.0017987366576986022}, 'final_train_score': 0.9999994730667081, 'test_score': 0.953569955446563}\n"
     ]
    }
   ],
   "source": [
    "#=============Or you can train your own model and make predictions\n",
    "if __name__ == \"__main__\":\n",
    "    # You can replace it with your own dataset\n",
    "    data_split_save = \"./data/mouse_glioma\"\n",
    "    df_train = pd.read_csv(f\"{data_split_save}/train_with_labels.csv\")\n",
    "    df_test = pd.read_csv(f\"{data_split_save}/test_with_labels.csv\")\n",
    "    X_train = df_train.drop(columns=['label', 'ID']).values  \n",
    "    X_test = df_test.drop(columns=['label', 'ID']).values  \n",
    "    y_train = df_train['label'].values \n",
    "    y_test = df_test['label'].values\n",
    "    groups = df_train['ID'].values\n",
    "  \n",
    "    print(\"Training set size:\", len(X_train))\n",
    "    print(\"Test set size:\", len(X_test))  \n",
    "\n",
    "    save_path = \"./out\"\n",
    "\n",
    "    folds = cv_folds(X_train, y_train, groups, n_splits=5, save_dir=f\"{data_split_save}/cv_folds\")\n",
    "    # Taking ML logistic regression and DL CNN as examples respectively\n",
    "    model_list = [\n",
    "        {\"model_type\": \"ml\", \"model_name\": \"logreg\", \"objective_fn\": objective_ml_model, \"test_fn\": test_ml_model},\n",
    "        #{\"model_type\": \"dl\", \"model_name\": \"cnn\", \"objective_fn\": objective_dl_model, \"test_fn\": test_dl_model},\n",
    "    ]\n",
    "\n",
    "    results = {}\n",
    "    SEED = 1\n",
    "    device = torch.device(\"cuda:5\") \n",
    "    for m in model_list:\n",
    "        print(f\"\\nðŸ”§ Running model: {m['model_name']} ({m['model_type']})\")\n",
    "\n",
    "        result = run_model_pipeline(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            X_test,\n",
    "            y_test,\n",
    "            folds,\n",
    "            model_type=m[\"model_type\"],\n",
    "            model_name=m[\"model_name\"],\n",
    "            objective_fn=m[\"objective_fn\"],\n",
    "            test_fn=m[\"test_fn\"],\n",
    "            search_space=None,  # You can also define your own search space for each model\n",
    "            n_trials=50,\n",
    "            score_metric=\"auroc\",\n",
    "            save_path=save_path,\n",
    "            device=device,\n",
    "            seed=SEED\n",
    "        )\n",
    "        print(f'{m[\"model_name\"]}:{result}')\n",
    "        results[m[\"model_name\"]] = result\n",
    "\n",
    "    print(\"\\nðŸ“Š The results of all models: \")\n",
    "    for name, res in results.items():\n",
    "        print(f\"{name}: {res}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The DL operation takes longer, so it is recommended to run it via the command line.\n",
    "# Run on the terminal:\n",
    "\"python train_pipeline.py\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamba-ssm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
